.. This file is automatically generated. Do not edit this file directly.

Google BigQuery Python Samples
===============================================================================

This directory contains samples for Google BigQuery. `Google BigQuery`_ is Google's fully managed, petabyte scale, low cost analytics data warehouse. BigQuery is NoOps—there is no infrastructure to manage and you don't need a database administrator—so you can focus on analyzing data to find meaningful insights, use familiar SQL, and take advantage of our pay-as-you-go model.


This sample shows how to use Data Manipulation Language with BigQuery.


.. _Google BigQuery: https://cloud.google.com/bigquery/docs 

Setup
-------------------------------------------------------------------------------


Authentication
++++++++++++++

Authentication is typically done through `Application Default Credentials`_,
which means you do not have to change the code to authenticate as long as
your environment has credentials. You have a few options for setting up
authentication:

#. When running locally, use the `Google Cloud SDK`_

    .. code-block:: bash

        gcloud beta auth application-default login


#. When running on App Engine or Compute Engine, credentials are already
   set-up. However, you may need to configure your Compute Engine instance
   with `additional scopes`_.

#. You can create a `Service Account key file`_. This file can be used to
   authenticate to Google Cloud Platform services from any environment. To use
   the file, set the ``GOOGLE_APPLICATION_CREDENTIALS`` environment variable to
   the path to the key file, for example:

    .. code-block:: bash

        export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service_account.json

.. _Application Default Credentials: https://cloud.google.com/docs/authentication#getting_credentials_for_server-centric_flow
.. _additional scopes: https://cloud.google.com/compute/docs/authentication#using
.. _Service Account key file: https://developers.google.com/identity/protocols/OAuth2ServiceAccount#creatinganaccount

Install Dependencies
++++++++++++++++++++

#. Install `pip`_ and `virtualenv`_ if you do not already have them.

#. Create a virtualenv. Samples are compatible with Python 2.7 and 3.4+.

    .. code-block:: bash

        $ virtualenv env
        $ source env/bin/activate

#. Install the dependencies needed to run the samples.

    .. code-block:: bash

        $ pip install -r requirements.txt

.. _pip: https://pip.pypa.io/
.. _virtualenv: https://virtualenv.pypa.io/

Samples
-------------------------------------------------------------------------------

Populate sample DB
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python populate_db.py

    usage: populate_db.py [-h] total_users host user password db
    
    Command-line tool to simulate user actions and write to SQL database.
    
    positional arguments:
      total_users  How many simulated users to create.
      host         Host of the database to write to.
      user         User to connect to the database.
      password     Password for the database user.
      db           Name of the database to write to.
    
    optional arguments:
      -h, --help   show this help message and exit


Insert SQL
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



To run this sample:

.. code-block:: bash

    $ python insert_sql.py

    usage: insert_sql.py [-h] project default_dataset sql_path
    
    Sample that runs a file containing INSERT SQL statements in Big Query.
    
    This could be used to run the INSERT statements in a mysqldump output such as
    
        mysqldump --user=root         --password='secret-password'         --host=127.0.0.1         --no-create-info sample_db         --skip-add-locks > sample_db_export.sql
    
    To run, first create tables with the same names and columns as the sample
    database. Then run this script.
    
        python insert_sql.py my-project my_dataset sample_db_export.sql
    
    positional arguments:
      project          Google Cloud project name
      default_dataset  Default BigQuery dataset name
      sql_path         Path to SQL file
    
    optional arguments:
      -h, --help       show this help message and exit




The client library
-------------------------------------------------------------------------------

This sample uses the `Google Cloud Client Library for Python`_.
You can read the documentation for more details on API usage and use GitHub
to `browse the source`_ and  `report issues`_.

.. Google Cloud Client Library for Python:
    https://googlecloudplatform.github.io/google-cloud-python/
.. browse the source:
    https://github.com/GoogleCloudPlatform/google-cloud-python
.. report issues:
    https://github.com/GoogleCloudPlatform/google-cloud-python/issues


.. _Google Cloud SDK: https://cloud.google.com/sdk/